{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiLayerPerceptron1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojasnadkar96/cs273p_project/blob/master/multiLayerPerceptron1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNPeLyI1bvnb",
        "colab_type": "text"
      },
      "source": [
        "# Multi-layer Perceptron (168 Features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ5l-n6Vb8IA",
        "colab_type": "text"
      },
      "source": [
        "Importing all the required libraries.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdc6YZOKh4dy",
        "colab_type": "code",
        "outputId": "882ec744-ee5c-4a60-b584-8d0acf56857c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UITSYJZHb_l3",
        "colab_type": "text"
      },
      "source": [
        "The two functions below are to save and import pickle files.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUXEQKmeh5Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_pkl(df,name):\n",
        "    fullname = name+'.pkl'\n",
        "    output = open(fullname, 'wb')\n",
        "    pickle.dump(df, output)\n",
        "    output.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0slPPJvh8je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_pkl(df,name):\n",
        "    fullname = name+'.pkl'\n",
        "    df = pickle.load(open(fullname, 'rb'))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwZ6BqRh-7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_valid = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train_l = pd.DataFrame()\n",
        "df_valid_l = pd.DataFrame()\n",
        "df_test_l = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRwp4lTtiBLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = import_pkl(df_train,'train_x')\n",
        "df_valid = import_pkl(df_valid,'valid_x')\n",
        "df_test = import_pkl(df_test,'test_x')\n",
        "df_train_l = import_pkl(df_train_l,'train_x_l')\n",
        "df_valid_l = import_pkl(df_valid_l,'valid_x_l')\n",
        "df_test_l = import_pkl(df_test_l,'test_x_l')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3Ld8WXqd_M",
        "colab_type": "code",
        "outputId": "6ca96306-66c8-44c1-eaaf-6b48ed374bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_valid.shape)\n",
        "print(df_test.shape)\n",
        "print(df_train_l.shape)\n",
        "print(df_valid_l.shape)\n",
        "print(df_test_l.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(77854, 168)\n",
            "(13737, 168)\n",
            "(10175, 168)\n",
            "(77854, 1)\n",
            "(13737, 1)\n",
            "(10175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asHDJaIJcDgn",
        "colab_type": "text"
      },
      "source": [
        "Pre-processed data with a total of 168 features has been imported into dataframes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuim48UqXgnv",
        "colab_type": "text"
      },
      "source": [
        "The input is set to 168 as there are 168 features in the dataset.<br>\n",
        "We initialize a random model with 3 hidden layers of size 256, 512 and 256 respectively.<br>\n",
        "The epochs are set to 25 and the batch size is set to 100.<br>\n",
        "We will test the accuracy on train and validation for this model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrNGXMIa8vVr",
        "colab_type": "code",
        "outputId": "70ecaf34-0ce0-4a6a-e316-21019053a34a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1234
        }
      },
      "source": [
        "test_model = Sequential()\n",
        "test_model.add(Dense(168, input_dim=168, activation='relu'))\n",
        "test_model.add(Dense(256, activation='relu'))\n",
        "test_model.add(Dense(512, activation='relu'))\n",
        "test_model.add(Dense(256, activation='relu'))\n",
        "test_model.add(Dense(1, activation='sigmoid'))\n",
        "test_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "test_model.fit(df_train, df_train_l, epochs=25, batch_size=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0613 22:19:32.034279 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0613 22:19:32.056976 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0613 22:19:32.060847 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0613 22:19:32.117051 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0613 22:19:32.137677 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0613 22:19:32.144017 140150942447488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0613 22:19:32.318176 140150942447488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 9s 110us/step - loss: 0.5483 - acc: 0.5112\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.4993 - acc: 0.5268\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4821 - acc: 0.5336\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 7s 96us/step - loss: 0.4698 - acc: 0.5330\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 8s 99us/step - loss: 0.4477 - acc: 0.5379\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4420 - acc: 0.5395\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4138 - acc: 0.5435\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.4149 - acc: 0.5422\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 8s 97us/step - loss: 0.3985 - acc: 0.5443\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.3877 - acc: 0.5475\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 8s 98us/step - loss: 0.3726 - acc: 0.5488\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.3586 - acc: 0.5502\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 7s 92us/step - loss: 0.3554 - acc: 0.5481\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.3361 - acc: 0.5478\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 7s 95us/step - loss: 0.3202 - acc: 0.5458\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.3202 - acc: 0.5465\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.2929 - acc: 0.5491\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 8s 98us/step - loss: 0.2837 - acc: 0.5488\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 7s 95us/step - loss: 0.2726 - acc: 0.5462\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 8s 97us/step - loss: 0.2535 - acc: 0.5491\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.2358 - acc: 0.5490\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.2238 - acc: 0.5517\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.2193 - acc: 0.5488\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.2074 - acc: 0.5502\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.2100 - acc: 0.5521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7732f13c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiGR3eUQ9o7B",
        "colab_type": "code",
        "outputId": "b5c788c0-3bf7-4fc8-a550-7935efbbb3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_train = test_model.evaluate(df_train,df_train_l)\n",
        "print(\"score: \", score_train[1]*100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77854/77854 [==============================] - 3s 40us/step\n",
            "score:  55.28296555074985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9V8t5Uy-AGB",
        "colab_type": "code",
        "outputId": "c301fd61-73c8-415f-f899-07f07ff74659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_valid = test_model.evaluate(df_valid,df_valid_l)\n",
        "print(\"score: \", score_valid[1]*100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13737/13737 [==============================] - 1s 40us/step\n",
            "score:  52.194802358593584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff72rRkB-ArJ",
        "colab_type": "code",
        "outputId": "5e5e31cb-980e-4935-e6ec-7ec7ddb0e261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_test = test_model.evaluate(df_test,df_test_l)\n",
        "print(\"score: \", score_test[1]*100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10175/10175 [==============================] - 0s 38us/step\n",
            "score:  52.99262899262899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKWB6LuIYyKw",
        "colab_type": "text"
      },
      "source": [
        "The train, validation and test accuracy is: 55.2%, 52.1% and 52.9% respectively.<br>\n",
        "Let us see if we can increase this accuracy by tuning the parameters.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y69NQnLNZGuk",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "We will tune the optimizer.<br>\n",
        "We have options between `adam` and `SGD`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URDYOmIIw1SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_1(optimizer='adam'):\n",
        "  model_1 = Sequential()\n",
        "  model_1.add(Dense(168, input_dim=168, activation='relu'))\n",
        "  model_1.add(Dense(256, activation='relu'))\n",
        "  model_1.add(Dense(512, activation='relu'))\n",
        "  model_1.add(Dense(256, activation='relu'))\n",
        "  model_1.add(Dense(1, activation='sigmoid'))\n",
        "  model_1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9YiTsah0tUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = KerasClassifier(build_fn=nn_model_1, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrzeIqccDeB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = ['SGD', 'Adam']\n",
        "param_grid_1 = dict(optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFrvgHhDqIy",
        "colab_type": "code",
        "outputId": "bd444207-d42d-4408-c503-c2d7f9c29a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_2 = GridSearchCV(estimator=model_1, param_grid=param_grid_1, n_jobs=4, verbose=1, cv=2)\n",
        "grid_2.fit(df_train,df_train_l)\n",
        "grid_2.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  5.1min remaining:  5.1min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  5.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 10s 122us/step - loss: 0.6513 - acc: 0.4213\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.5780 - acc: 0.5126\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.5374 - acc: 0.5350\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.5174 - acc: 0.5385\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.5048 - acc: 0.5425\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.4942 - acc: 0.5429\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.4855 - acc: 0.5414\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4775 - acc: 0.5441\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4707 - acc: 0.5447\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.4628 - acc: 0.5458\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4538 - acc: 0.5472\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4463 - acc: 0.5495\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4370 - acc: 0.5500\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 8s 98us/step - loss: 0.4278 - acc: 0.5522\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.4184 - acc: 0.5528\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4072 - acc: 0.5549\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.3953 - acc: 0.5544\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.3829 - acc: 0.5585\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.3708 - acc: 0.5594\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.3570 - acc: 0.5633\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.3415 - acc: 0.5623\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.3282 - acc: 0.5654\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.3127 - acc: 0.5675\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 8s 99us/step - loss: 0.2944 - acc: 0.5670\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.2758 - acc: 0.5720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'SGD'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf72qvGSZpex",
        "colab_type": "text"
      },
      "source": [
        "Optimal optmizer is `SGD`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVUEoEo-Z0vt",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "We will tune the Initialization.<br>\n",
        "We have options between `uniform` and `normal`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g16wzF1Fxfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_2(init_mode='uniform'):\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(Dense(168, input_dim=168, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(256, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(512, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(256, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "  model_2.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "  return model_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpQkBGzrJEZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = KerasClassifier(build_fn=nn_model_2, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDngWEbfJH-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_mode = ['uniform','normal']\n",
        "param_grid_2 = dict(init_mode=init_mode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSZ4HIt1JeAX",
        "colab_type": "code",
        "outputId": "336310dc-dbbc-4330-9f85-01638f6a733a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_2 = GridSearchCV(estimator=model_2, param_grid=param_grid_2, n_jobs=4, verbose=1, cv=2)\n",
        "grid_2.fit(df_train,df_train_l)\n",
        "grid_2.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  4.9min remaining:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  5.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 10s 127us/step - loss: 0.6850 - acc: 0.3493\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.6824 - acc: 0.3493\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.6821 - acc: 0.3493\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.6816 - acc: 0.3493\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.6808 - acc: 0.3493\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.6792 - acc: 0.3493\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.6750 - acc: 0.3493\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.6599 - acc: 0.3541\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.6108 - acc: 0.4776\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.5566 - acc: 0.5338\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.5290 - acc: 0.5445\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.5160 - acc: 0.5455\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.5062 - acc: 0.5468\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.4992 - acc: 0.5471\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.4919 - acc: 0.5483\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.4866 - acc: 0.5475\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.4806 - acc: 0.5469\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 9s 110us/step - loss: 0.4748 - acc: 0.5464\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4700 - acc: 0.5486\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4647 - acc: 0.5491\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.4577 - acc: 0.5488\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.4521 - acc: 0.5498\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.4453 - acc: 0.5511\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4378 - acc: 0.5533\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4291 - acc: 0.5521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'init_mode': 'uniform'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYQgl0uCaBeF",
        "colab_type": "text"
      },
      "source": [
        "Optimal Initialization is `uniform`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OjPHOIjaD7P",
        "colab_type": "text"
      },
      "source": [
        "### Activation Function\n",
        "\n",
        "We will tune the Activation Function.<br>\n",
        "We have options between `relu` and `softmax`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdKzsWpBLFUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_3(activation='relu'):\n",
        "  model_3 = Sequential()\n",
        "  model_3.add(Dense(168, input_dim=168, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(256, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(512, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(256, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "  model_3.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "  return model_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCsoiMaGLdQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = KerasClassifier(build_fn=nn_model_3, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgD73X7jLlqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = ['softmax','relu']\n",
        "param_grid_3 = dict(activation=activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD6oBO16LwP7",
        "colab_type": "code",
        "outputId": "2acb551c-6c42-4326-9725-2b801590e5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_3 = GridSearchCV(estimator=model_3, param_grid=param_grid_3, n_jobs=4, verbose=1, cv=2)\n",
        "grid_3.fit(df_train,df_train_l)\n",
        "grid_3.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  4.9min remaining:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  5.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 10s 124us/step - loss: 0.6851 - acc: 0.3495\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.6825 - acc: 0.3493\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6822 - acc: 0.3493\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6819 - acc: 0.3493\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6814 - acc: 0.3493\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.6804 - acc: 0.3493\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.6783 - acc: 0.3493\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.6720 - acc: 0.3493\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.6467 - acc: 0.3766\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.5851 - acc: 0.5137\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.5417 - acc: 0.5414\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.5223 - acc: 0.5459\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.5119 - acc: 0.5449\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 8s 99us/step - loss: 0.5038 - acc: 0.5449\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4975 - acc: 0.5467\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.4905 - acc: 0.5480\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.4841 - acc: 0.5467\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4777 - acc: 0.5494\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4743 - acc: 0.5485\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4679 - acc: 0.5491\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4620 - acc: 0.5506\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4586 - acc: 0.5516\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 8s 100us/step - loss: 0.4515 - acc: 0.5533\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 8s 101us/step - loss: 0.4448 - acc: 0.5543\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4383 - acc: 0.5534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZk9lDcYaUAj",
        "colab_type": "text"
      },
      "source": [
        "Optimal Activation Function is `relu`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn-Mz1N-akN-",
        "colab_type": "text"
      },
      "source": [
        "### Final Model\n",
        "\n",
        "We will use the tuned parameters and check accuracy.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_UaHofzSt4z",
        "colab_type": "code",
        "outputId": "0004bc6e-d9c3-4af6-f862-b3679978d435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "model_final = Sequential()\n",
        "model_final.add(Dense(168, input_dim=168, kernel_initializer='uniform', activation='relu'))\n",
        "model_final.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final.add(Dense(512, kernel_initializer='uniform', activation='relu'))\n",
        "model_final.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "model_final.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "model_final.fit(df_train,df_train_l,epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 10s 128us/step - loss: 0.6850 - acc: 0.3496\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.6824 - acc: 0.3493\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.6820 - acc: 0.3493\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6815 - acc: 0.3493\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6807 - acc: 0.3493\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6789 - acc: 0.3493\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.6738 - acc: 0.3493\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.6547 - acc: 0.3651\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.5983 - acc: 0.4950\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.5468 - acc: 0.5358\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.5230 - acc: 0.5444\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.5109 - acc: 0.5463\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.5035 - acc: 0.5482\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.4958 - acc: 0.5459\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4890 - acc: 0.5471\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 8s 107us/step - loss: 0.4826 - acc: 0.5466\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 9s 112us/step - loss: 0.4765 - acc: 0.5482\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4710 - acc: 0.5485\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 8s 106us/step - loss: 0.4650 - acc: 0.5501\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.4591 - acc: 0.5492\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 8s 103us/step - loss: 0.4527 - acc: 0.5529\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.4451 - acc: 0.5521\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.4402 - acc: 0.5505\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 8s 102us/step - loss: 0.4298 - acc: 0.5516\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.4210 - acc: 0.5524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb61791cd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBdCk6NW5Rz",
        "colab_type": "code",
        "outputId": "210e7ce3-2de7-46a1-b43c-cc9d4ae592dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_train_f = model_final.evaluate(df_train,df_train_l)\n",
        "print(\"score: \", score_train_f[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77854/77854 [==============================] - 6s 80us/step\n",
            "score:  56.07033678500276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFPqDYnkdpP",
        "colab_type": "code",
        "outputId": "44c04e99-395a-4156-b424-b5aebe135e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_valid_f = model_final.evaluate(df_valid,df_valid_l)\n",
        "print(\"score: \", score_valid_f[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13737/13737 [==============================] - 1s 72us/step\n",
            "score:  53.068355536143265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vLuUiQzkkWj",
        "colab_type": "code",
        "outputId": "2e003b10-e56a-4b16-9a3a-21bbd49aa450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_test_f = model_final.evaluate(df_test,df_test_l)\n",
        "print(\"score: \", score_test_f[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10175/10175 [==============================] - 1s 74us/step\n",
            "score:  53.631449631449634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5urYLwqa2W1",
        "colab_type": "text"
      },
      "source": [
        "The train, validation and test accuracy is: 56%, 53.1% and 53.6% respectively.<br>\n",
        "This seems like the better model and therfore we keep these hyperparameters.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VurKILUMd5Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}