{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiLayerPerceptron2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojasnadkar96/cs273p_project/blob/master/multiLayerPerceptron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ey-4vjbrKt",
        "colab_type": "text"
      },
      "source": [
        "# Multi-layer Perceptron (PCA - 24 features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsff3tPactoZ",
        "colab_type": "text"
      },
      "source": [
        "Importing all the required libraries.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdc6YZOKh4dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rjJex05dUX4",
        "colab_type": "text"
      },
      "source": [
        "The two functions below are to save and import pickle files.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUXEQKmeh5Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_pkl(df,name):\n",
        "    fullname = name+'.pkl'\n",
        "    output = open(fullname, 'wb')\n",
        "    pickle.dump(df, output)\n",
        "    output.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0slPPJvh8je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_pkl(df,name):\n",
        "    fullname = name+'.pkl'\n",
        "    df = pickle.load(open(fullname, 'rb'))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwZ6BqRh-7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.DataFrame()\n",
        "df_valid = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "df_train_l = pd.DataFrame()\n",
        "df_valid_l = pd.DataFrame()\n",
        "df_test_l = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRwp4lTtiBLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = import_pkl(df_train,'train_x')\n",
        "df_valid = import_pkl(df_valid,'valid_x')\n",
        "df_test = import_pkl(df_test,'test_x')\n",
        "df_train_l = import_pkl(df_train_l,'train_x_l')\n",
        "df_valid_l = import_pkl(df_valid_l,'valid_x_l')\n",
        "df_test_l = import_pkl(df_test_l,'test_x_l')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc3Ld8WXqd_M",
        "colab_type": "code",
        "outputId": "e8830f61-0e8a-4676-93b7-f83fc83642d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print(df_train.shape)\n",
        "print(df_valid.shape)\n",
        "print(df_test.shape)\n",
        "print(df_train_l.shape)\n",
        "print(df_valid_l.shape)\n",
        "print(df_test_l.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(77854, 168)\n",
            "(13737, 168)\n",
            "(10175, 168)\n",
            "(77854, 1)\n",
            "(13737, 1)\n",
            "(10175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rEQmxx9dbaB",
        "colab_type": "text"
      },
      "source": [
        "Pre-processed data with a total of 168 features has been imported into dataframes.<br>\n",
        "We will apply PCA on these datasets to reduce the dimensionality of this data.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNo3jd6uuXOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "dims = []\n",
        "variances = []\n",
        "optimum_dim = 168\n",
        "threshold=0.01\n",
        "for dim in range(1, 168):\n",
        "    pca = PCA(n_components=dim)\n",
        "    pca.fit(df_train)\n",
        "    variance = np.array(pca.explained_variance_ratio_)\n",
        "    variance = variance.min()\n",
        "    if threshold < variance:\n",
        "        optimum_dim = dim\n",
        "        dims.append(dim)\n",
        "        variances.append(variance)\n",
        "    else:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPrsT8sudm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "38a6967e-4dd4-4b29-d125-9b1fa68d238a"
      },
      "source": [
        "print(optimum_dim)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(dims, variances)\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npLAQEZGYFBYiIhKTwkJERGL6/5wfQ2Ck9F0uAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flhVA0-5dk48",
        "colab_type": "text"
      },
      "source": [
        "Optimal value for PCA is 24 features, as we can see in the graph above.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqXuvQ9buevI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7534cdaa-0e11-4d5a-a263-5b54258d39e8"
      },
      "source": [
        "pca = PCA(n_components=24)\n",
        "pca_train = pca.fit_transform(df_train)\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02895799 0.02233207 0.01973592 0.01650457 0.01473513 0.01347959\n",
            " 0.01341078 0.01308768 0.01292678 0.01249606 0.01235684 0.01218551\n",
            " 0.01218051 0.01213256 0.01208663 0.01204374 0.01199178 0.01195113\n",
            " 0.01188193 0.01177171 0.01159093 0.01151983 0.01088789 0.01072156]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkCrGQfrdqIH",
        "colab_type": "text"
      },
      "source": [
        "We have now reduced the train dataset into 24 features using PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvJQe468ePHo",
        "colab_type": "text"
      },
      "source": [
        "The input is set to 24 as there are 24 features in the reduced dataset.<br>\n",
        "We initialize a random model with 3 hidden layers of size 256, 512 and 256 respectively.<br>\n",
        "The epochs are set to 25 and the batch size is set to 100.<br>\n",
        "We will test the accuracy on train and validation for this model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrNGXMIa8vVr",
        "colab_type": "code",
        "outputId": "4d7b7a7b-3048-4e8a-d920-4c145c1956fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "test_model = Sequential()\n",
        "test_model.add(Dense(24, input_dim=24, activation='relu'))\n",
        "test_model.add(Dense(256, activation='relu'))\n",
        "test_model.add(Dense(512, activation='relu'))\n",
        "test_model.add(Dense(256, activation='relu'))\n",
        "test_model.add(Dense(1, activation='sigmoid'))\n",
        "test_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "test_model.fit(pca_train, df_train_l, epochs=25, batch_size=100)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 8s 104us/step - loss: 0.6430 - acc: 0.4553\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 7s 86us/step - loss: 0.6126 - acc: 0.4652\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5990 - acc: 0.4793\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.5914 - acc: 0.4832\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5861 - acc: 0.4856\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 6s 82us/step - loss: 0.5816 - acc: 0.4904\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 6s 82us/step - loss: 0.5771 - acc: 0.4927\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 6s 83us/step - loss: 0.5708 - acc: 0.4947\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 7s 85us/step - loss: 0.5631 - acc: 0.4975\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5592 - acc: 0.4938\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 6s 83us/step - loss: 0.5540 - acc: 0.4987\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5497 - acc: 0.5004\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 6s 82us/step - loss: 0.5491 - acc: 0.5021\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 7s 85us/step - loss: 0.5438 - acc: 0.5018\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.5357 - acc: 0.5042\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 7s 85us/step - loss: 0.5342 - acc: 0.5055\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 7s 85us/step - loss: 0.5296 - acc: 0.5062\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 6s 82us/step - loss: 0.5353 - acc: 0.5085\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 6s 83us/step - loss: 0.5169 - acc: 0.5096\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5156 - acc: 0.5110\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 6s 79us/step - loss: 0.5148 - acc: 0.5091\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 6s 79us/step - loss: 0.5162 - acc: 0.5116\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 6s 76us/step - loss: 0.5049 - acc: 0.5117\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 6s 79us/step - loss: 0.4977 - acc: 0.5122\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 6s 80us/step - loss: 0.4922 - acc: 0.5142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe722eb978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiGR3eUQ9o7B",
        "colab_type": "code",
        "outputId": "7ae46cd0-876b-43a7-98b5-6a7b4de06362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_train = test_model.evaluate(pca_train,df_train_l)\n",
        "print(\"score: \", score_train[1]*100)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77854/77854 [==============================] - 4s 57us/step\n",
            "score:  50.65764122695619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9V8t5Uy-AGB",
        "colab_type": "code",
        "outputId": "3f76731a-a2dc-41ca-8efc-19017a02b7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "pca_valid = pca.transform(df_valid)\n",
        "score_valid = test_model.evaluate(pca_valid,df_valid_l)\n",
        "print(\"score: \", score_valid[1]*100)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13737/13737 [==============================] - 1s 55us/step\n",
            "score:  47.50673363907695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff72rRkB-ArJ",
        "colab_type": "code",
        "outputId": "2c8b2ae8-16ef-4663-bf57-bdef12882347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "pca_test = pca.transform(df_test)\n",
        "score_test = test_model.evaluate(pca_test,df_test_l)\n",
        "print(\"score: \", score_test[1]*100)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10175/10175 [==============================] - 1s 52us/step\n",
            "score:  48.10810810810811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH194g4IeZZM",
        "colab_type": "text"
      },
      "source": [
        "The train, validation and test accuracy is: 50%, 47.5% and 48.1% respectively.<br>\n",
        "Let us see if we can increase this accuracy by tuning the parameters.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTKT2DSbelkp",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "We will tune the optimizer.<br>\n",
        "We have options between `adam` and `SGD`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URDYOmIIw1SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_1(optimizer='adam'):\n",
        "  model_1 = Sequential()\n",
        "  model_1.add(Dense(24, input_dim=24, activation='relu'))\n",
        "  model_1.add(Dense(256, activation='relu'))\n",
        "  model_1.add(Dense(512, activation='relu'))\n",
        "  model_1.add(Dense(256, activation='relu'))\n",
        "  model_1.add(Dense(1, activation='sigmoid'))\n",
        "  model_1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9YiTsah0tUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = KerasClassifier(build_fn=nn_model_1, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrzeIqccDeB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = ['SGD', 'Adam']\n",
        "param_grid_1 = dict(optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFrvgHhDqIy",
        "colab_type": "code",
        "outputId": "92c6800a-0e9d-491b-f1eb-140304a4486c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_2 = GridSearchCV(estimator=model_1, param_grid=param_grid_1, n_jobs=4, verbose=1, cv=2)\n",
        "grid_2.fit(pca_train,df_train_l)\n",
        "grid_2.best_params_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  3.0min remaining:  3.0min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 7s 86us/step - loss: 0.6509 - acc: 0.4522\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.6163 - acc: 0.4781\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5985 - acc: 0.4868\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5823 - acc: 0.4934\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5788 - acc: 0.4952\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5769 - acc: 0.4981\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5700 - acc: 0.4975\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5601 - acc: 0.4995\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.5602 - acc: 0.4987\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 6s 76us/step - loss: 0.5505 - acc: 0.5020\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5448 - acc: 0.5026\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5452 - acc: 0.5034\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5383 - acc: 0.5040\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5387 - acc: 0.5026\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5292 - acc: 0.5057\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5284 - acc: 0.5064\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 6s 76us/step - loss: 0.5238 - acc: 0.5080\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5139 - acc: 0.5084\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5189 - acc: 0.5095\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5141 - acc: 0.5105\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5009 - acc: 0.5120\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5037 - acc: 0.5093\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5001 - acc: 0.5103\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.4961 - acc: 0.5131\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.4811 - acc: 0.5130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'Adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4xYxfnteqoP",
        "colab_type": "text"
      },
      "source": [
        "Optimal optmizer is `Adam`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ED41U6etYk",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "We will tune the Initialization.<br>\n",
        "We have options between `uniform` and `normal`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g16wzF1Fxfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_2(init_mode='uniform'):\n",
        "  model_2 = Sequential()\n",
        "  model_2.add(Dense(24, input_dim=24, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(256, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(512, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(256, kernel_initializer=init_mode, activation='relu'))\n",
        "  model_2.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
        "  model_2.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  return model_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpQkBGzrJEZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = KerasClassifier(build_fn=nn_model_2, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDngWEbfJH-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_mode = ['uniform','normal']\n",
        "param_grid_2 = dict(init_mode=init_mode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSZ4HIt1JeAX",
        "colab_type": "code",
        "outputId": "c27184c6-f955-4388-c5a2-2b67ccb1b1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_2 = GridSearchCV(estimator=model_2, param_grid=param_grid_2, n_jobs=4, verbose=1, cv=2)\n",
        "grid_2.fit(pca_train,df_train_l)\n",
        "grid_2.best_params_"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  3.9min remaining:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  3.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.6468 - acc: 0.4592\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.6189 - acc: 0.4847\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.6096 - acc: 0.4881\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5987 - acc: 0.4890\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.6170 - acc: 0.4912\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.6134 - acc: 0.4910\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.5874 - acc: 0.4926\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5901 - acc: 0.4934\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5791 - acc: 0.4931\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5809 - acc: 0.4960\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5880 - acc: 0.4956\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.5850 - acc: 0.4973\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 5s 71us/step - loss: 0.5791 - acc: 0.4974\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 5s 69us/step - loss: 0.5717 - acc: 0.4999\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 5s 69us/step - loss: 0.5689 - acc: 0.4983\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 5s 69us/step - loss: 0.5685 - acc: 0.5027\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5651 - acc: 0.5006\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5625 - acc: 0.5005\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 6s 78us/step - loss: 0.5654 - acc: 0.5026\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5719 - acc: 0.5006\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5642 - acc: 0.5054\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5566 - acc: 0.5040\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 6s 71us/step - loss: 0.5571 - acc: 0.5013\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.5594 - acc: 0.5016\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 5s 70us/step - loss: 0.5576 - acc: 0.5056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'init_mode': 'uniform'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou4gXoQRe2b9",
        "colab_type": "text"
      },
      "source": [
        "Optimal Initialization is `uniform`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HyhhhPFe3rQ",
        "colab_type": "text"
      },
      "source": [
        "### Activation Function\n",
        "\n",
        "We will tune the Activation Function.<br>\n",
        "We have options between `relu` and `softmax`<br>\n",
        "We will use GridSearchCV on top of Keras to tune the parameter.<br>\n",
        "The epochs and batchsize is kept the same as for above model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdKzsWpBLFUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model_3(activation='relu'):\n",
        "  model_3 = Sequential()\n",
        "  model_3.add(Dense(24, input_dim=24, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(256, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(512, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(256, kernel_initializer='uniform', activation=activation))\n",
        "  model_3.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "  model_3.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  return model_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCsoiMaGLdQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3 = KerasClassifier(build_fn=nn_model_3, epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgD73X7jLlqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = ['softmax','relu']\n",
        "param_grid_3 = dict(activation=activation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD6oBO16LwP7",
        "colab_type": "code",
        "outputId": "26a26c78-e0e1-42ce-9aa4-95a6d4658389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_3 = GridSearchCV(estimator=model_3, param_grid=param_grid_3, n_jobs=4, verbose=1, cv=2)\n",
        "grid_3.fit(pca_train,df_train_l)\n",
        "grid_3.best_params_"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:  3.9min remaining:  3.9min\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  4.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 8s 105us/step - loss: 0.6468 - acc: 0.4515\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 7s 86us/step - loss: 0.6112 - acc: 0.4852\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 7s 92us/step - loss: 0.5914 - acc: 0.4937\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 7s 94us/step - loss: 0.5852 - acc: 0.4933\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 7s 89us/step - loss: 0.5801 - acc: 0.4949\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 7s 88us/step - loss: 0.5777 - acc: 0.4938\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.5749 - acc: 0.4961\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 7s 90us/step - loss: 0.5733 - acc: 0.4974\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5881 - acc: 0.4952\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5659 - acc: 0.4981\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 6s 78us/step - loss: 0.5659 - acc: 0.5011\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 7s 91us/step - loss: 0.5627 - acc: 0.4973\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5526 - acc: 0.5030\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5557 - acc: 0.5007\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 7s 91us/step - loss: 0.5529 - acc: 0.5019\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.5528 - acc: 0.5006\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 7s 87us/step - loss: 0.5499 - acc: 0.5015\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 6s 76us/step - loss: 0.5461 - acc: 0.5062\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 6s 78us/step - loss: 0.5455 - acc: 0.5040\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 7s 87us/step - loss: 0.5471 - acc: 0.5031\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 6s 77us/step - loss: 0.5458 - acc: 0.5043\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5395 - acc: 0.5052\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 7s 87us/step - loss: 0.5374 - acc: 0.5037\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5447 - acc: 0.4995\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 6s 83us/step - loss: 0.5368 - acc: 0.5030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6ZWyStsfA-H",
        "colab_type": "text"
      },
      "source": [
        "Optimal Activation Function is `relu`<br>\n",
        "We'll use this from now on.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzd9D78RfEpd",
        "colab_type": "text"
      },
      "source": [
        "### Final Model 1\n",
        "\n",
        "We will use the tuned parameters and check accuracy.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_UaHofzSt4z",
        "colab_type": "code",
        "outputId": "a9119dea-f50d-4747-817d-5b955c95ee93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        }
      },
      "source": [
        "model_final1 = Sequential()\n",
        "model_final1.add(Dense(24, input_dim=24, kernel_initializer='uniform', activation='relu'))\n",
        "model_final1.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final1.add(Dense(512, kernel_initializer='uniform', activation='relu'))\n",
        "model_final1.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final1.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "model_final1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_final1.fit(pca_train,df_train_l,epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 9s 118us/step - loss: 0.6470 - acc: 0.4551\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 8s 98us/step - loss: 0.6143 - acc: 0.4850\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 8s 98us/step - loss: 0.6018 - acc: 0.4912\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 7s 93us/step - loss: 0.5926 - acc: 0.4920\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 7s 92us/step - loss: 0.5818 - acc: 0.4958\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 7s 84us/step - loss: 0.5767 - acc: 0.4970\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5755 - acc: 0.4961\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5667 - acc: 0.4979\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 6s 74us/step - loss: 0.5741 - acc: 0.4972\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 7s 86us/step - loss: 0.5707 - acc: 0.4969\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.5713 - acc: 0.5008\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.5612 - acc: 0.4988\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5681 - acc: 0.5004\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 6s 80us/step - loss: 0.5560 - acc: 0.5007\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 7s 85us/step - loss: 0.5637 - acc: 0.4998\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 6s 73us/step - loss: 0.5564 - acc: 0.5023\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5522 - acc: 0.5011\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 6s 77us/step - loss: 0.5486 - acc: 0.5044\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 6s 80us/step - loss: 0.5504 - acc: 0.4995\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 6s 80us/step - loss: 0.5482 - acc: 0.5010\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 6s 79us/step - loss: 0.5467 - acc: 0.5021\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 6s 80us/step - loss: 0.5556 - acc: 0.5004\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 6s 72us/step - loss: 0.5411 - acc: 0.5021\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 6s 75us/step - loss: 0.5373 - acc: 0.5019\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 7s 89us/step - loss: 0.5437 - acc: 0.5025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe7328dcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmBdCk6NW5Rz",
        "colab_type": "code",
        "outputId": "552c6476-2d0a-4084-a4a2-01a384b10d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_train_f1 = model_final1.evaluate(pca_train,df_train_l)\n",
        "print(\"score: \", score_train_f1[1]*100)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77854/77854 [==============================] - 5s 59us/step\n",
            "score:  52.02815526498318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFPqDYnkdpP",
        "colab_type": "code",
        "outputId": "bc2eb84e-eb7f-43b0-d8bf-4b38ced6f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_valid_f1 = model_final1.evaluate(pca_valid,df_valid_l)\n",
        "print(\"score: \", score_valid_f1[1]*100)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13737/13737 [==============================] - 1s 59us/step\n",
            "score:  49.836208779209436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vLuUiQzkkWj",
        "colab_type": "code",
        "outputId": "aa7745cc-28e4-4284-ca18-fde746180acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "score_test_f1 = model_final1.evaluate(pca_test,df_test_l)\n",
        "print(\"score: \", score_test_f1[1]*100)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10175/10175 [==============================] - 1s 63us/step\n",
            "score:  49.307125307125304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ux5ILmdfQHj",
        "colab_type": "text"
      },
      "source": [
        "The train, validation and test accuracy is: 52%, 49.8% and 49.3% respectively.<br>\n",
        "This is not a good accuracy as it is almost like the random model we selected.<br>\n",
        "Now, we will use the same hyperparameters which we used for the 168 feature dataset<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHGHvFSnft3f",
        "colab_type": "text"
      },
      "source": [
        "### Final Model 2\n",
        "\n",
        "We will use the tuned parameters from 168 parameter model and check accuracy.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj3VkS_fo1Y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "outputId": "a3139868-7959-4901-d9e1-e2d6727bab5c"
      },
      "source": [
        "model_final2 = Sequential()\n",
        "model_final2.add(Dense(24, input_dim=24, kernel_initializer='uniform', activation='relu'))\n",
        "model_final2.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final2.add(Dense(512, kernel_initializer='uniform', activation='relu'))\n",
        "model_final2.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
        "model_final2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "model_final2.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "model_final2.fit(pca_train,df_train_l,epochs=25, batch_size=100, verbose=1)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "77854/77854 [==============================] - 6s 81us/step - loss: 0.6851 - acc: 0.3501\n",
            "Epoch 2/25\n",
            "77854/77854 [==============================] - 5s 64us/step - loss: 0.6826 - acc: 0.3493\n",
            "Epoch 3/25\n",
            "77854/77854 [==============================] - 5s 64us/step - loss: 0.6825 - acc: 0.3493\n",
            "Epoch 4/25\n",
            "77854/77854 [==============================] - 5s 64us/step - loss: 0.6824 - acc: 0.3493\n",
            "Epoch 5/25\n",
            "77854/77854 [==============================] - 5s 63us/step - loss: 0.6824 - acc: 0.3493\n",
            "Epoch 6/25\n",
            "77854/77854 [==============================] - 5s 62us/step - loss: 0.6823 - acc: 0.3493\n",
            "Epoch 7/25\n",
            "77854/77854 [==============================] - 5s 63us/step - loss: 0.6822 - acc: 0.3493\n",
            "Epoch 8/25\n",
            "77854/77854 [==============================] - 5s 62us/step - loss: 0.6820 - acc: 0.3493\n",
            "Epoch 9/25\n",
            "77854/77854 [==============================] - 5s 59us/step - loss: 0.6818 - acc: 0.3493\n",
            "Epoch 10/25\n",
            "77854/77854 [==============================] - 5s 63us/step - loss: 0.6814 - acc: 0.3493\n",
            "Epoch 11/25\n",
            "77854/77854 [==============================] - 5s 63us/step - loss: 0.6809 - acc: 0.3493\n",
            "Epoch 12/25\n",
            "77854/77854 [==============================] - 5s 62us/step - loss: 0.6800 - acc: 0.3493\n",
            "Epoch 13/25\n",
            "77854/77854 [==============================] - 5s 63us/step - loss: 0.6785 - acc: 0.3493\n",
            "Epoch 14/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6756 - acc: 0.3493\n",
            "Epoch 15/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6704 - acc: 0.3493\n",
            "Epoch 16/25\n",
            "77854/77854 [==============================] - 5s 62us/step - loss: 0.6626 - acc: 0.3932\n",
            "Epoch 17/25\n",
            "77854/77854 [==============================] - 5s 62us/step - loss: 0.6554 - acc: 0.4462\n",
            "Epoch 18/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6514 - acc: 0.4553\n",
            "Epoch 19/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6487 - acc: 0.4585\n",
            "Epoch 20/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6464 - acc: 0.4565\n",
            "Epoch 21/25\n",
            "77854/77854 [==============================] - 5s 59us/step - loss: 0.6440 - acc: 0.4582\n",
            "Epoch 22/25\n",
            "77854/77854 [==============================] - 5s 60us/step - loss: 0.6412 - acc: 0.4614\n",
            "Epoch 23/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6384 - acc: 0.4666\n",
            "Epoch 24/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6354 - acc: 0.4699\n",
            "Epoch 25/25\n",
            "77854/77854 [==============================] - 5s 61us/step - loss: 0.6327 - acc: 0.4738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe71d6c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWEsh2IU5Lo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eebc405c-c1b2-450e-e1af-0a9dfb0f6fe3"
      },
      "source": [
        "score_train_f2 = model_final2.evaluate(pca_train,df_train_l)\n",
        "print(\"score: \", score_train_f2[1]*100)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77854/77854 [==============================] - 4s 57us/step\n",
            "score:  46.72592288129062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvsbH-qc5WZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f2f7b32c-5632-4fc7-8bb9-f4528e8a4ae4"
      },
      "source": [
        "score_valid_f2 = model_final2.evaluate(pca_valid,df_valid_l)\n",
        "print(\"score: \", score_valid_f2[1]*100)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13737/13737 [==============================] - 1s 55us/step\n",
            "score:  45.73050884472592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_KNOecG5jEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7176707d-e98b-41e9-c995-6c6e431582cf"
      },
      "source": [
        "score_test_f2 = model_final2.evaluate(pca_test,df_test_l)\n",
        "print(\"score: \", score_test_f2[1]*100)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10175/10175 [==============================] - 1s 52us/step\n",
            "score:  46.77149877149877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzrYGEf4iKcz",
        "colab_type": "text"
      },
      "source": [
        "The train, validation and test accuracy is: 46.7%, 45.7% and 46.7% respectively.<br>\n",
        "This model is not overfitting much, but the accuracies are low.<br>\n",
        "We will proceed with Final Model 1 as the final model.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YdWLGm05_Cm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9114a6a8-71c3-4d2e-d5b8-b6d882642aac"
      },
      "source": [
        "scores = [score_train_f1[1]*100,score_valid_f1[1]*100,score_test_f1[1]*100]\n",
        "labels = ['train','validation','test']\n",
        "plt.title(\"Accuracy for MLP (PCA)\")\n",
        "plt.plot(labels, scores, marker='o', color = \"r\", label = \"Final model scores\")\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7My4+A3MyszDn4zszLz/06dc0NK69gLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E535oQRiiwMV",
        "colab_type": "text"
      },
      "source": [
        "Above is the graph for training, validation and test accuracy for the best model (Final Model 1)<br>"
      ]
    }
  ]
}